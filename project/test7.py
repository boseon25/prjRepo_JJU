import os
import json
import streamlit as st
import numpy as np
import re
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# âœ… OpenAI GPT ëª¨ë¸ ì´ˆê¸°í™”
chat_model = ChatOpenAI(model_name="gpt-4o", temperature=0.1)

# âœ… Streamlit UI ì„¤ì •
st.set_page_config(page_title="ì „ì£¼ëŒ€í•™êµ ë¹„êµê³¼ ì±—ë´‡", page_icon="ğŸ“", layout="centered")
st.title("ğŸ“ ì „ì£¼ëŒ€í•™êµ ë¹„êµê³¼ ì±—ë´‡")
st.write("ì „ì£¼ëŒ€í•™êµ ë¹„êµê³¼ í”„ë¡œê·¸ë¨ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”!")

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (KeyError ë°©ì§€)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# âœ… JSON ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_program_data():
    file_path = r"C:\Users\user\Desktop\Github\prjRepo_JJU\project\programs.json"
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            data = json.load(file)

        possible_keys = ["í”„ë¡œê·¸ë¨_ì •ë³´", "ë¹„êµê³¼_í”„ë¡œê·¸ë¨", "í”„ë¡œê·¸ë¨"]
        for key in possible_keys:
            if key in data:
                return data[key]

        return []
    except Exception as e:
        st.error(f"âŒ JSON ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return []

program_data = load_program_data()

# âœ… OpenAI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")

# âœ… JSON ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ ì €ì¥ (ì„ë² ë”©ìœ¼ë¡œ ì €ì¥)
@st.cache_data
def create_embeddings(data):
    if not data:
        return np.array([])
    texts = [f"{item['ì œëª©']} {item['ì„¤ëª…']} {item.get('ì‹ ì²­ëŒ€ìƒ', '')} {item.get('í˜œíƒ', '')}" for item in data]
    embeddings = embeddings_model.embed_documents(texts)
    return np.array(embeddings)

program_embeddings = create_embeddings(program_data)

# âœ… í‚¤ì›Œë“œ ë° í•„í„°ë§ ì¡°ê±´ ì¶”ì¶œ
def extract_filters(query):
    query_lower = query.lower()

    # íŠ¹ì • ì›” í•„í„° (ex: "2ì›”", "3ì›”")
    month_match = re.findall(r"(\d{4}\.\d{2})", query_lower)

    # íŠ¹ì • ê¸°ê°„ í•„í„° (ex: "2025.02.10 ~ 2025.02.20")
    date_range_match = re.search(r"(\d{4}\.\d{2}\.\d{2})\s*~\s*(\d{4}\.\d{2}\.\d{2})", query_lower)

    # íŠ¹ì • í‚¤ì›Œë“œ ê°ì§€
    keywords = ["ì í”„ì—…", "ì í”„ì—… í¬ì¸íŠ¸", "ì í”„ì—… ìê¸°ì£¼ë„í˜• í¬ì¸íŠ¸", "ì í”„ì—… í”„ë¡œê·¸ë¨", "ë¹„êµê³¼ í¬ì¸íŠ¸", "ncs", "ë©˜í† ë§", "ì°½ì—…", "ìê²©ì¦", "íŠ¹ê°•", "ì·¨ì—…"]
    matched_keywords = [kw for kw in keywords if kw in query_lower]

    # "ì í”„ì—…"ì´ í¬í•¨ë˜ë©´ ê´€ë ¨ëœ ëª¨ë“  í•­ëª©ì„ ê²€ìƒ‰í•˜ë„ë¡ ì„¤ì •
    if "ì í”„ì—…" in query_lower:
        matched_keywords.extend(["ì í”„ì—… í¬ì¸íŠ¸", "ì í”„ì—… ìê¸°ì£¼ë„í˜• í¬ì¸íŠ¸", "ì í”„ì—… í”„ë¡œê·¸ë¨"])

    # íŠ¹ì • ëŒ€ìƒ í•„í„° (ex: "3í•™ë…„", "1í•™ë…„", "ì¡¸ì—… ì˜ˆì •ì")
    target_match = re.search(r"(\dí•™ë…„|ì¡¸ì—… ì˜ˆì •ì)", query_lower)
    target_filter = target_match.group(1) if target_match else None

    return month_match, date_range_match, matched_keywords, target_filter

# âœ… ë¹„êµê³¼ í”„ë¡œê·¸ë¨ ê²€ìƒ‰ í•¨ìˆ˜
def find_program(query):
    month_match, date_range_match, matched_keywords, target_filter = extract_filters(query)
    results = []

    for program in program_data:
        title = program.get("ì œëª©", "").lower()
        description = program.get("ì„¤ëª…", "").lower()
        period = program.get("ê¸°ê°„", "").lower()
        benefits = program.get("í˜œíƒ", "").lower()
        target = program.get("ì‹ ì²­ëŒ€ìƒ", "").lower()

        # íŠ¹ì • ì›” í¬í•¨ í•„í„°ë§
        if month_match and not any(month in period for month in month_match):
            continue  

        # íŠ¹ì • í‚¤ì›Œë“œ í•„í„°ë§
        if matched_keywords and not any(kw in description or kw in title or kw in benefits for kw in matched_keywords):
            continue

        # íŠ¹ì • ëŒ€ìƒ(í•™ë…„) í•„í„°ë§
        if target_filter and target_filter not in target:
            continue

        results.append(program)

    return results

# âœ… RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (GPTê°€ JSON ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±)
def generate_rag_response(query):
    results = find_program(query)

    if results:
        gpt_prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
        ê²€ìƒ‰ëœ ë¹„êµê³¼ í”„ë¡œê·¸ë¨ ëª©ë¡:
        {json.dumps(results, indent=2, ensure_ascii=False)}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.
        """
    else:
        gpt_prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
        ê´€ë ¨ëœ ë¹„êµê³¼ í”„ë¡œê·¸ë¨ì´ ë°ì´í„°ì— ëª…í™•íˆ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ìœ ì‚¬í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ìµœì„ ì„ ë‹¤í• ê²Œìš”.
        """

    response = chat_model.invoke(gpt_prompt)
    return response.content

# âœ… ì±„íŒ… UI
chat_container = st.container()

# âœ… ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for msg in st.session_state["messages"]:
    with chat_container:
        if isinstance(msg, HumanMessage):
            with st.chat_message("user"):
                st.write(msg.content)
        elif isinstance(msg, AIMessage):
            with st.chat_message("assistant"):
                st.write(msg.content)

# âœ… ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë¹„êµê³¼ í”„ë¡œê·¸ë¨ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”!")

if user_input:
    st.session_state["messages"].append(HumanMessage(content=user_input))

    # âœ… GPTë¥¼ í™œìš©í•˜ì—¬ JSON ë°ì´í„° ê¸°ë°˜ ì‘ë‹µ ìƒì„±
    response_content = generate_rag_response(user_input)

    st.session_state["messages"].append(AIMessage(content=response_content))

    # âœ… ì±„íŒ… UI ì¦‰ì‹œ ê°±ì‹ 
    with chat_container:
        with st.chat_message("user"):
            st.write(user_input)
        with st.chat_message("assistant"):
            st.write(response_content)
